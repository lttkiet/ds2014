{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28eaca1b",
   "metadata": {
    "papermill": {
     "duration": 0.002628,
     "end_time": "2025-12-19T13:07:20.271246",
     "exception": false,
     "start_time": "2025-12-19T13:07:20.268618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Xây dựng kiến trúc Encoder-Decoder gồm 3 lớp LSTM cho module encoder và 3 lớp LSTM cho module decoder, với hidden size là 256, cho bài toán dịch máy từ tiếng Anh sang tiếng Việt. Huấn luyện mô hình này trên bộ dữ liệu PhoMT sử dụng Adam làm phương thức tối ưu tham số. Đánh giá độ hiệu quả của mô hình sử dụng độ đo ROUGE-L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d597e3af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:07:20.276192Z",
     "iopub.status.busy": "2025-12-19T13:07:20.275770Z",
     "iopub.status.idle": "2025-12-19T13:07:27.231331Z",
     "shell.execute_reply": "2025-12-19T13:07:27.230327Z"
    },
    "papermill": {
     "duration": 6.959851,
     "end_time": "2025-12-19T13:07:27.232838",
     "exception": false,
     "start_time": "2025-12-19T13:07:20.272987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt các thư viện cần thiết\n",
    "%pip -q install torch rouge-score tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c06126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:07:27.238339Z",
     "iopub.status.busy": "2025-12-19T13:07:27.237664Z",
     "iopub.status.idle": "2025-12-19T13:07:33.115167Z",
     "shell.execute_reply": "2025-12-19T13:07:33.114493Z"
    },
    "papermill": {
     "duration": 5.882113,
     "end_time": "2025-12-19T13:07:33.116902",
     "exception": false,
     "start_time": "2025-12-19T13:07:27.234789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "HID_DIM = 256\n",
    "EMB_DIM = 256\n",
    "N_LAYERS = 3\n",
    "DROPOUT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 10\n",
    "TEACHER_FORCING = 0.5\n",
    "MAX_LEN = 120\n",
    "LR = 1e-3\n",
    "\n",
    "TRAIN_PATH = \"/kaggle/input/small-phomt/train.json\"\n",
    "DEV_PATH = \"/kaggle/input/small-phomt/dev.json\"\n",
    "TEST_PATH = \"/kaggle/input/small-phomt/test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0bb363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:07:33.122159Z",
     "iopub.status.busy": "2025-12-19T13:07:33.121518Z",
     "iopub.status.idle": "2025-12-19T13:07:33.343587Z",
     "shell.execute_reply": "2025-12-19T13:07:33.342839Z"
    },
    "papermill": {
     "duration": 0.226296,
     "end_time": "2025-12-19T13:07:33.345138",
     "exception": false,
     "start_time": "2025-12-19T13:07:33.118842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/dev/test sizes: 20000/2000/2000\n"
     ]
    }
   ],
   "source": [
    "def load_split(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_split(TRAIN_PATH)\n",
    "dev_data = load_split(DEV_PATH)\n",
    "test_data = load_split(TEST_PATH)\n",
    "\n",
    "print(f\"Train/dev/test sizes: {len(train_data)}/{len(dev_data)}/{len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "959af3a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:07:33.350241Z",
     "iopub.status.busy": "2025-12-19T13:07:33.349901Z",
     "iopub.status.idle": "2025-12-19T13:07:33.783052Z",
     "shell.execute_reply": "2025-12-19T13:07:33.782317Z"
    },
    "papermill": {
     "duration": 0.437384,
     "end_time": "2025-12-19T13:07:33.784554",
     "exception": false,
     "start_time": "2025-12-19T13:07:33.347170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src vocab: 10015 | Tgt vocab: 4264\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text: str) -> List[str]:\n",
    "    # Tách từ đơn giản giữ lại dấu câu\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text.lower())\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, texts: List[str], min_freq: int = 2):\n",
    "        self.pad_token = \"<pad>\"\n",
    "        self.unk_token = \"<unk>\"\n",
    "        self.bos_token = \"<bos>\"\n",
    "        self.eos_token = \"<eos>\"\n",
    "        specials = [self.pad_token, self.unk_token, self.bos_token, self.eos_token]\n",
    "\n",
    "        counter = Counter()\n",
    "        for line in texts:\n",
    "            counter.update(tokenize(line))\n",
    "\n",
    "        tokens = [tok for tok, cnt in counter.items() if cnt >= min_freq]\n",
    "        self.itos = specials + sorted(tokens)\n",
    "        self.stoi = {tok: idx for idx, tok in enumerate(self.itos)}\n",
    "\n",
    "        self.pad_idx = self.stoi[self.pad_token]\n",
    "        self.unk_idx = self.stoi[self.unk_token]\n",
    "        self.bos_idx = self.stoi[self.bos_token]\n",
    "        self.eos_idx = self.stoi[self.eos_token]\n",
    "\n",
    "    def encode(self, text: str) -> List[int]:\n",
    "        return [self.stoi.get(tok, self.unk_idx) for tok in tokenize(text)]\n",
    "\n",
    "    def decode(self, ids: List[int]) -> str:\n",
    "        tokens = []\n",
    "        for idx in ids:\n",
    "            if idx == self.eos_idx:\n",
    "                break\n",
    "            if idx in (self.pad_idx, self.bos_idx):\n",
    "                continue\n",
    "            tokens.append(self.itos[idx])\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "src_vocab = Vocab([ex[\"english\"] for ex in train_data], min_freq=2)\n",
    "tgt_vocab = Vocab([ex[\"vietnamese\"] for ex in train_data], min_freq=2)\n",
    "\n",
    "print(f\"Src vocab: {len(src_vocab.itos)} | Tgt vocab: {len(tgt_vocab.itos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95d18ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:07:33.789842Z",
     "iopub.status.busy": "2025-12-19T13:07:33.789433Z",
     "iopub.status.idle": "2025-12-19T13:07:33.798092Z",
     "shell.execute_reply": "2025-12-19T13:07:33.797303Z"
    },
    "papermill": {
     "duration": 0.012801,
     "end_time": "2025-12-19T13:07:33.799380",
     "exception": false,
     "start_time": "2025-12-19T13:07:33.786579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: train 157, dev 16, test 16\n"
     ]
    }
   ],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, src_vocab: Vocab, tgt_vocab: Vocab, max_len: int):\n",
    "        self.data = data\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        src_ids = [self.src_vocab.bos_idx] + self.src_vocab.encode(sample[\"english\"])[: self.max_len - 2] + [self.src_vocab.eos_idx]\n",
    "        tgt_ids = [self.tgt_vocab.bos_idx] + self.tgt_vocab.encode(sample[\"vietnamese\"])[: self.max_len - 2] + [self.tgt_vocab.eos_idx]\n",
    "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_seqs, tgt_seqs = zip(*batch)\n",
    "    src_padded = nn.utils.rnn.pad_sequence(src_seqs, batch_first=True, padding_value=src_vocab.pad_idx)\n",
    "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_seqs, batch_first=True, padding_value=tgt_vocab.pad_idx)\n",
    "    return src_padded, tgt_padded\n",
    "\n",
    "train_dataset = TranslationDataset(train_data, src_vocab, tgt_vocab, MAX_LEN)\n",
    "dev_dataset = TranslationDataset(dev_data, src_vocab, tgt_vocab, MAX_LEN)\n",
    "test_dataset = TranslationDataset(test_data, src_vocab, tgt_vocab, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "src_vocab_size = len(src_vocab.itos)\n",
    "tgt_vocab_size = len(tgt_vocab.itos)\n",
    "\n",
    "print(f\"Batches: train {len(train_loader)}, dev {len(dev_loader)}, test {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a2c4ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:07:33.804312Z",
     "iopub.status.busy": "2025-12-19T13:07:33.804076Z",
     "iopub.status.idle": "2025-12-19T13:07:33.815218Z",
     "shell.execute_reply": "2025-12-19T13:07:33.814528Z"
    },
    "papermill": {
     "duration": 0.015343,
     "end_time": "2025-12-19T13:07:33.816584",
     "exception": false,
     "start_time": "2025-12-19T13:07:33.801241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float, pad_idx: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float, pad_idx: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.embedding(input)\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        logits = self.fc_out(output.squeeze(1))\n",
    "        return logits, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio: float = 0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size, device=self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        input_token = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            logits, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs[:, t, :] = logits\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = logits.argmax(1)\n",
    "            input_token = trg[:, t] if teacher_force else top1\n",
    "        return outputs\n",
    "\n",
    "    def greedy_decode(self, src, max_len: int):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_size = src.size(0)\n",
    "            hidden, cell = self.encoder(src)\n",
    "            input_token = torch.full((batch_size,), tgt_vocab.bos_idx, dtype=torch.long, device=self.device)\n",
    "            outputs = []\n",
    "            for _ in range(max_len):\n",
    "                logits, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "                next_token = logits.argmax(1)\n",
    "                outputs.append(next_token.unsqueeze(1))\n",
    "                input_token = next_token\n",
    "            return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b058d561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:07:33.821684Z",
     "iopub.status.busy": "2025-12-19T13:07:33.821301Z",
     "iopub.status.idle": "2025-12-19T13:07:38.716465Z",
     "shell.execute_reply": "2025-12-19T13:07:38.715833Z"
    },
    "papermill": {
     "duration": 4.899506,
     "end_time": "2025-12-19T13:07:38.718116",
     "exception": false,
     "start_time": "2025-12-19T13:07:33.818610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(src_vocab_size, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, src_vocab.pad_idx)\n",
    "decoder = Decoder(tgt_vocab_size, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, tgt_vocab.pad_idx)\n",
    "model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for src, tgt in tqdm(loader, desc=\"train\", leave=False):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(src, tgt, teacher_forcing_ratio=TEACHER_FORCING)\n",
    "        logits = outputs[:, 1:].reshape(-1, tgt_vocab_size)\n",
    "        gold = tgt[:, 1:].reshape(-1)\n",
    "        loss = criterion(logits, gold)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate_loss(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(loader, desc=\"eval\", leave=False):\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            outputs = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "            logits = outputs[:, 1:].reshape(-1, tgt_vocab_size)\n",
    "            gold = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(logits, gold)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89a36dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:07:38.723546Z",
     "iopub.status.busy": "2025-12-19T13:07:38.723208Z",
     "iopub.status.idle": "2025-12-19T13:15:05.149463Z",
     "shell.execute_reply": "2025-12-19T13:15:05.148605Z"
    },
    "papermill": {
     "duration": 446.430892,
     "end_time": "2025-12-19T13:15:05.151195",
     "exception": false,
     "start_time": "2025-12-19T13:07:38.720303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train 6.2670 | dev 6.2269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train 6.0436 | dev 6.1590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train 5.9680 | dev 6.1543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train 5.8786 | dev 6.1486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train 5.7622 | dev 6.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train 5.6535 | dev 6.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train 5.5723 | dev 6.0851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train 5.4844 | dev 6.0623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train 5.4106 | dev 6.0552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train 5.3531 | dev 6.0390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dev = math.inf\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss = train_epoch(model, train_loader)\n",
    "    dev_loss = evaluate_loss(model, dev_loader)\n",
    "    if dev_loss < best_dev:\n",
    "        best_dev = dev_loss\n",
    "        torch.save(model.state_dict(), \"best_seq2seq.pt\")\n",
    "    print(f\"Epoch {epoch}: train {train_loss:.4f} | dev {dev_loss:.4f}\")\n",
    "\n",
    "# Tải mô hình tốt nhất sau khi huấn luyện\n",
    "model.load_state_dict(torch.load(\"best_seq2seq.pt\", map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be11ab71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:15:05.275078Z",
     "iopub.status.busy": "2025-12-19T13:15:05.274762Z",
     "iopub.status.idle": "2025-12-19T13:15:06.854947Z",
     "shell.execute_reply": "2025-12-19T13:15:06.854188Z"
    },
    "papermill": {
     "duration": 1.642123,
     "end_time": "2025-12-19T13:15:06.856786",
     "exception": false,
     "start_time": "2025-12-19T13:15:05.214663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L trên tập test: 0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def translate_batch(model, src_batch: torch.Tensor):\n",
    "    src_batch = src_batch.to(DEVICE)\n",
    "    preds = model.greedy_decode(src_batch, max_len=MAX_LEN)\n",
    "    outputs = []\n",
    "    for seq in preds:\n",
    "        outputs.append(tgt_vocab.decode(seq.tolist()))\n",
    "    return outputs\n",
    "\n",
    "def compute_rouge(model, loader):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "    scores = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(loader, desc=\"rouge\", leave=False):\n",
    "            pred_texts = translate_batch(model, src)\n",
    "            tgt_texts = []\n",
    "            for seq in tgt:\n",
    "                tgt_texts.append(tgt_vocab.decode(seq.tolist()))\n",
    "            for pred, ref in zip(pred_texts, tgt_texts):\n",
    "                score = scorer.score(ref, pred)[\"rougeL\"].fmeasure\n",
    "                scores.append(score)\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "rouge_l = compute_rouge(model, test_loader)\n",
    "print(f\"ROUGE-L trên tập test: {rouge_l:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9045978,
     "sourceId": 14187853,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 472.225801,
   "end_time": "2025-12-19T13:15:10.040931",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-19T13:07:17.815130",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
