{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658de588",
   "metadata": {
    "papermill": {
     "duration": 0.003222,
     "end_time": "2025-12-19T06:55:53.485222",
     "exception": false,
     "start_time": "2025-12-19T06:55:53.482000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Xây dựng kiến trúc Encoder-Decoder gồm 3 lớp LSTM cho module encoder và 3 lớp LSTM cho module decoder, với hidden size là 256, cho bài toán dịch máy từ tiếng Anh sang tiếng Việt. Huấn luyện mô hình này trên bộ dữ liệu PhoMT sử dụng Adam làm phương thức tối ưu tham số. Đánh giá độ hiệu quả của mô hình sử dụng độ đo ROUGE-L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea13d306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T06:55:53.491484Z",
     "iopub.status.busy": "2025-12-19T06:55:53.491099Z",
     "iopub.status.idle": "2025-12-19T06:56:02.949825Z",
     "shell.execute_reply": "2025-12-19T06:56:02.948405Z"
    },
    "papermill": {
     "duration": 9.46444,
     "end_time": "2025-12-19T06:56:02.952068",
     "exception": false,
     "start_time": "2025-12-19T06:55:53.487628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt các thư viện cần thiết\n",
    "%pip -q install torch rouge-score tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a013b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T06:56:02.963488Z",
     "iopub.status.busy": "2025-12-19T06:56:02.962016Z",
     "iopub.status.idle": "2025-12-19T06:56:11.502892Z",
     "shell.execute_reply": "2025-12-19T06:56:11.501702Z"
    },
    "papermill": {
     "duration": 8.54982,
     "end_time": "2025-12-19T06:56:11.505365",
     "exception": false,
     "start_time": "2025-12-19T06:56:02.955545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from rouge_score import rouge_scorer\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "HID_DIM = 256\n",
    "EMB_DIM = 256\n",
    "N_LAYERS = 3\n",
    "DROPOUT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "N_EPOCHS = 10\n",
    "TEACHER_FORCING = 0.5\n",
    "MAX_LEN = 120\n",
    "LR = 1e-3\n",
    "\n",
    "TRAIN_PATH = \"/kaggle/input/small-phomt/train.json\"\n",
    "DEV_PATH = \"/kaggle/input/small-phomt/dev.json\"\n",
    "TEST_PATH = \"/kaggle/input/small-phomt/test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "049e28be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T06:56:11.512164Z",
     "iopub.status.busy": "2025-12-19T06:56:11.511641Z",
     "iopub.status.idle": "2025-12-19T06:56:11.693874Z",
     "shell.execute_reply": "2025-12-19T06:56:11.692657Z"
    },
    "papermill": {
     "duration": 0.188071,
     "end_time": "2025-12-19T06:56:11.696061",
     "exception": false,
     "start_time": "2025-12-19T06:56:11.507990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/dev/test sizes: 20000/2000/2000\n"
     ]
    }
   ],
   "source": [
    "def load_split(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_split(TRAIN_PATH)\n",
    "dev_data = load_split(DEV_PATH)\n",
    "test_data = load_split(TEST_PATH)\n",
    "\n",
    "print(f\"Train/dev/test sizes: {len(train_data)}/{len(dev_data)}/{len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ab2412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T06:56:11.703323Z",
     "iopub.status.busy": "2025-12-19T06:56:11.702824Z",
     "iopub.status.idle": "2025-12-19T06:56:12.259911Z",
     "shell.execute_reply": "2025-12-19T06:56:12.258786Z"
    },
    "papermill": {
     "duration": 0.563188,
     "end_time": "2025-12-19T06:56:12.262008",
     "exception": false,
     "start_time": "2025-12-19T06:56:11.698820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src vocab: 10015 | Tgt vocab: 4264\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text: str) -> List[str]:\n",
    "    # Tách từ đơn giản giữ lại dấu câu\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\", text.lower())\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, texts: List[str], min_freq: int = 2):\n",
    "        self.pad_token = \"<pad>\"\n",
    "        self.unk_token = \"<unk>\"\n",
    "        self.bos_token = \"<bos>\"\n",
    "        self.eos_token = \"<eos>\"\n",
    "        specials = [self.pad_token, self.unk_token, self.bos_token, self.eos_token]\n",
    "\n",
    "        counter = Counter()\n",
    "        for line in texts:\n",
    "            counter.update(tokenize(line))\n",
    "\n",
    "        tokens = [tok for tok, cnt in counter.items() if cnt >= min_freq]\n",
    "        self.itos = specials + sorted(tokens)\n",
    "        self.stoi = {tok: idx for idx, tok in enumerate(self.itos)}\n",
    "\n",
    "        self.pad_idx = self.stoi[self.pad_token]\n",
    "        self.unk_idx = self.stoi[self.unk_token]\n",
    "        self.bos_idx = self.stoi[self.bos_token]\n",
    "        self.eos_idx = self.stoi[self.eos_token]\n",
    "\n",
    "    def encode(self, text: str) -> List[int]:\n",
    "        return [self.stoi.get(tok, self.unk_idx) for tok in tokenize(text)]\n",
    "\n",
    "    def decode(self, ids: List[int]) -> str:\n",
    "        tokens = []\n",
    "        for idx in ids:\n",
    "            if idx == self.eos_idx:\n",
    "                break\n",
    "            if idx in (self.pad_idx, self.bos_idx):\n",
    "                continue\n",
    "            tokens.append(self.itos[idx])\n",
    "        return \" \".join(tokens)\n",
    "\n",
    "src_vocab = Vocab([ex[\"english\"] for ex in train_data], min_freq=2)\n",
    "tgt_vocab = Vocab([ex[\"vietnamese\"] for ex in train_data], min_freq=2)\n",
    "\n",
    "print(f\"Src vocab: {len(src_vocab.itos)} | Tgt vocab: {len(tgt_vocab.itos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e032c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T06:56:12.269929Z",
     "iopub.status.busy": "2025-12-19T06:56:12.269171Z",
     "iopub.status.idle": "2025-12-19T06:56:12.280607Z",
     "shell.execute_reply": "2025-12-19T06:56:12.279662Z"
    },
    "papermill": {
     "duration": 0.01773,
     "end_time": "2025-12-19T06:56:12.282545",
     "exception": false,
     "start_time": "2025-12-19T06:56:12.264815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: train 157, dev 16, test 16\n"
     ]
    }
   ],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data, src_vocab: Vocab, tgt_vocab: Vocab, max_len: int):\n",
    "        self.data = data\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        src_ids = [self.src_vocab.bos_idx] + self.src_vocab.encode(sample[\"english\"])[: self.max_len - 2] + [self.src_vocab.eos_idx]\n",
    "        tgt_ids = [self.tgt_vocab.bos_idx] + self.tgt_vocab.encode(sample[\"vietnamese\"])[: self.max_len - 2] + [self.tgt_vocab.eos_idx]\n",
    "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_seqs, tgt_seqs = zip(*batch)\n",
    "    src_padded = nn.utils.rnn.pad_sequence(src_seqs, batch_first=True, padding_value=src_vocab.pad_idx)\n",
    "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_seqs, batch_first=True, padding_value=tgt_vocab.pad_idx)\n",
    "    return src_padded, tgt_padded\n",
    "\n",
    "train_dataset = TranslationDataset(train_data, src_vocab, tgt_vocab, MAX_LEN)\n",
    "dev_dataset = TranslationDataset(dev_data, src_vocab, tgt_vocab, MAX_LEN)\n",
    "test_dataset = TranslationDataset(test_data, src_vocab, tgt_vocab, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "src_vocab_size = len(src_vocab.itos)\n",
    "tgt_vocab_size = len(tgt_vocab.itos)\n",
    "\n",
    "print(f\"Batches: train {len(train_loader)}, dev {len(dev_loader)}, test {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f7fefbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T06:56:12.290095Z",
     "iopub.status.busy": "2025-12-19T06:56:12.289706Z",
     "iopub.status.idle": "2025-12-19T06:56:12.305343Z",
     "shell.execute_reply": "2025-12-19T06:56:12.304343Z"
    },
    "papermill": {
     "duration": 0.021948,
     "end_time": "2025-12-19T06:56:12.307333",
     "exception": false,
     "start_time": "2025-12-19T06:56:12.285385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float, pad_idx: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float, pad_idx: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(1)\n",
    "        embedded = self.embedding(input)\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        logits = self.fc_out(output.squeeze(1))\n",
    "        return logits, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder, device: torch.device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio: float = 0.5):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1)\n",
    "        vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, vocab_size, device=self.device)\n",
    "        hidden, cell = self.encoder(src)\n",
    "\n",
    "        input_token = trg[:, 0]\n",
    "        for t in range(1, trg_len):\n",
    "            logits, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "            outputs[:, t, :] = logits\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = logits.argmax(1)\n",
    "            input_token = trg[:, t] if teacher_force else top1\n",
    "        return outputs\n",
    "\n",
    "    def greedy_decode(self, src, max_len: int):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_size = src.size(0)\n",
    "            hidden, cell = self.encoder(src)\n",
    "            input_token = torch.full((batch_size,), tgt_vocab.bos_idx, dtype=torch.long, device=self.device)\n",
    "            outputs = []\n",
    "            for _ in range(max_len):\n",
    "                logits, hidden, cell = self.decoder(input_token, hidden, cell)\n",
    "                next_token = logits.argmax(1)\n",
    "                outputs.append(next_token.unsqueeze(1))\n",
    "                input_token = next_token\n",
    "            return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20de8279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T06:56:12.314620Z",
     "iopub.status.busy": "2025-12-19T06:56:12.314282Z",
     "iopub.status.idle": "2025-12-19T06:56:19.303663Z",
     "shell.execute_reply": "2025-12-19T06:56:19.302688Z"
    },
    "papermill": {
     "duration": 6.995748,
     "end_time": "2025-12-19T06:56:19.305949",
     "exception": false,
     "start_time": "2025-12-19T06:56:12.310201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(src_vocab_size, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, src_vocab.pad_idx)\n",
    "decoder = Decoder(tgt_vocab_size, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT, tgt_vocab.pad_idx)\n",
    "model = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)\n",
    "\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for src, tgt in tqdm(loader, desc=\"train\", leave=False):\n",
    "        src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(src, tgt, teacher_forcing_ratio=TEACHER_FORCING)\n",
    "        logits = outputs[:, 1:].reshape(-1, tgt_vocab_size)\n",
    "        gold = tgt[:, 1:].reshape(-1)\n",
    "        loss = criterion(logits, gold)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def evaluate_loss(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(loader, desc=\"eval\", leave=False):\n",
    "            src, tgt = src.to(DEVICE), tgt.to(DEVICE)\n",
    "            outputs = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "            logits = outputs[:, 1:].reshape(-1, tgt_vocab_size)\n",
    "            gold = tgt[:, 1:].reshape(-1)\n",
    "            loss = criterion(logits, gold)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2763546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T06:56:19.314000Z",
     "iopub.status.busy": "2025-12-19T06:56:19.313082Z",
     "iopub.status.idle": "2025-12-19T13:12:24.032451Z",
     "shell.execute_reply": "2025-12-19T13:12:24.031452Z"
    },
    "papermill": {
     "duration": 22564.725736,
     "end_time": "2025-12-19T13:12:24.034633",
     "exception": false,
     "start_time": "2025-12-19T06:56:19.308897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train 6.2661 | dev 6.2546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: train 6.1065 | dev 6.2349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: train 6.0832 | dev 6.2466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: train 6.0467 | dev 6.2533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: train 5.9761 | dev 6.2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: train 5.8386 | dev 6.2594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: train 5.7261 | dev 6.2363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: train 5.6484 | dev 6.2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: train 5.5817 | dev 6.2075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: train 5.5134 | dev 6.2028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dev = math.inf\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss = train_epoch(model, train_loader)\n",
    "    dev_loss = evaluate_loss(model, dev_loader)\n",
    "    if dev_loss < best_dev:\n",
    "        best_dev = dev_loss\n",
    "        torch.save(model.state_dict(), \"best_seq2seq.pt\")\n",
    "    print(f\"Epoch {epoch}: train {train_loss:.4f} | dev {dev_loss:.4f}\")\n",
    "\n",
    "# Tải mô hình tốt nhất sau khi huấn luyện\n",
    "model.load_state_dict(torch.load(\"best_seq2seq.pt\", map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81801a35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T13:12:24.217004Z",
     "iopub.status.busy": "2025-12-19T13:12:24.216594Z",
     "iopub.status.idle": "2025-12-19T13:12:53.176591Z",
     "shell.execute_reply": "2025-12-19T13:12:53.175615Z"
    },
    "papermill": {
     "duration": 29.054231,
     "end_time": "2025-12-19T13:12:53.178586",
     "exception": false,
     "start_time": "2025-12-19T13:12:24.124355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-L trên tập test: 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def translate_batch(model, src_batch: torch.Tensor):\n",
    "    src_batch = src_batch.to(DEVICE)\n",
    "    preds = model.greedy_decode(src_batch, max_len=MAX_LEN)\n",
    "    outputs = []\n",
    "    for seq in preds:\n",
    "        outputs.append(tgt_vocab.decode(seq.tolist()))\n",
    "    return outputs\n",
    "\n",
    "def compute_rouge(model, loader):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "    scores = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(loader, desc=\"rouge\", leave=False):\n",
    "            pred_texts = translate_batch(model, src)\n",
    "            tgt_texts = []\n",
    "            for seq in tgt:\n",
    "                tgt_texts.append(tgt_vocab.decode(seq.tolist()))\n",
    "            for pred, ref in zip(pred_texts, tgt_texts):\n",
    "                score = scorer.score(ref, pred)[\"rougeL\"].fmeasure\n",
    "                scores.append(score)\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "rouge_l = compute_rouge(model, test_loader)\n",
    "print(f\"ROUGE-L trên tập test: {rouge_l:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9045978,
     "sourceId": 14187853,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22626.679751,
   "end_time": "2025-12-19T13:12:56.617581",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-19T06:55:49.937830",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
